{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Problem 2: Design and Strategy </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    " Throughout this problem, we will use the Monte-Carlo nethod to find the optimal strategies.\n",
    "    <\\font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Die:\n",
    "    #This class represent a faire Die\n",
    "    def __init__(self,n_sides=6):\n",
    "        self.faces = list(range(1,n_sides+1))\n",
    "        \n",
    "    def role_once(self):\n",
    "        #sample a face from uniform distribution\n",
    "        return np.random.choice(self.faces)\n",
    "    \n",
    "    def __call__(self):\n",
    "        sample = self.role_once()\n",
    "        return 'E' if sample%2 == 0 else 'O'\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A : Checking that the six-sided die is faire die\n",
    "<font size=\"4\">\n",
    "To do so, we will sample N samples from the die and look at the histogram plot\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Histogram of the six faced')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAaJElEQVR4nO3df5BV5Z3n8fdH2p/4A9SGNUCEjD1ONLVRplfJmEq5YgDND9gt2ZCZaMeQITUhiWazm2h2dogad0xVNiZWVqcYYbY1RmSIloxx4/SirpvMoDb+RnTp+AN6INDagCGMZjDf/eM8HQ/tvd33Qve9kufzqrp1z3me55zzPA31Oaefe24fRQRmZpaHQ5rdATMzaxyHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6NixJ6yWd2+x+NJOkfydps6Tdks6sof25knob0K/dkt6zH9sdKenvJO2S9Lej0bcqx31Q0mcbdTx7O4d+5iS9JOn8QWWflvTTgfWIOD0iHhxmP1MlhaSWUepqs30b+EJEHB0Rjw+uTGM/pdGdSv15YT82vQiYCJwQEfNHuFv2DubQt4PCO+BkcjKwvsl9GEknA/8vIvY2uyPWWA59G1b5twFJZ0nqlvSapG2SvpOaPZTed6Yphw9IOkTSn0t6WdJ2SbdIOq6030tS3auS/uug43xD0ipJP5D0GvDpdOx/lLRT0lZJ35d0WGl/IenzkjZK+qWkayT9XtrmNUkry+0HjbFiXyUdLmk3MAZ4UtLPK2w7MPYn09g/Uar7StrfVkmXlsoPl/RtSZvSz/GvJB1ZpW+nSPo/aSrmFUl3DBrzKZIOk/SEpC+m8jGSfibpLyrs7yrgL4BPpP4uTD+n+9O/xSuSbpM0rrTNFEl3SupLbb5fqvuMpA2Sdki6T9LJpboPS3ou9f37gCqN0RooIvzK+AW8BJw/qOzTwE8rtQH+Ebg4LR8NzEjLU4EAWkrbfQboAd6T2t4J3JrqTgN2Ax8EDqOYPvmX0nG+kdbnUVycHAn8ITADaEnH2wBcXjpeAKuBY4HTgTeANen4xwHPAh1Vfg5V+1ra9ylD/Bz3qQfOBfYCVwOHAhcCe4Dxqf67qa/HA8cAfwf8ZZV93w78l/RzOAL4YKXjAu8DdgDvTe3XAmOq7PMbwA9K66cAHwYOB1opTuLfTXVjgCeB64Gx5T6kf5+edMwW4M+Bf0h1JwKvUUwlHQp8Of1MPtvs//c5v5reAb+a/B+gCPTdwM7Saw/VQ/8h4CrgxEH7mcrbQ38N8PnS+qkpyFsorjRvL9UdBfyafUP/oWH6fjlwV2k9gHNK6+uAr5XW//tAkFXYV9W+lvZdb+j/86Cfx3aKk5aAXwG/V6r7APBilX3fAiwFJtdw3K8Az6Xwbxuiv/uEfoX6ecDjpb71lcdSave/gIWl9UPS/5+TgUuAtaU6Ab0O/ea+PL1jAPMiYtzAC/j8EG0XAr8PPCfpUUkfHaLtu4CXS+svUwT+xFS3eaAiIvYArw7afnN5RdLvS7pH0i/SlM9/o7iaLNtWWv7nCutH70df99erse+c+Z50/FaKk9y6NFW1E/hJKq/kqxSB+YiKO6k+M8QxOylOwPdGxMZaOyppgqQVkv4p/Wx/wFs/2ynAy1F5/v9k4HulcfSnvk7i7f/GwaB/U2s8h77VJSI2RsQngQnAt4BVksZSXHEOtoUiFAa8m+LX+23AVmDyQEWazz5h8OEGrd9EcRXbFhHHAl9n5OaIh+rrSHuF4gR0eulke1xEVDwhRcQvIuJPI+JdwOeAG4e4U+hG4B5gtqQP1tGnv6T4ef/r9LP9FG/9bDcD767yYfpm4HPli4aIODIi/oHi33jKQENJKq9bczj0rS6SPiWpNSJ+QzEVBPAmxa//v6GYEx9wO/BlSdMkHU1xZX5HumJcBXxM0h+lD1evYvgAP4Zijni3pD8A/mzEBjZ0X2uxjX3HXlX62f01cL2kCQCSJkmaXam9pPmSBk6QOyjC+c0K7S6m+Nzj08CXgM40llocQ5rmkzQJ+M+lukcoAvw6SWMlHSHpnFT3V8CVkk5PfThO0sAtoD8GTpf079MJ40vAv6qxPzZKHPpWrznA+nRHy/eABRHxepqeuRb4WfpVfwawHLiV4nOAF4HXgS8CRMT6tLyCIlB+STHn/cYQx/5PwB+ntn8N3DFE23pV7WuNvkERsjsl/Yca2n+N4gPQtWk65X9TfI5Qyb8BHk4/89XAZRHxYrmBpHdTfDh8SUTsjogfAt0UH77W4ipgOrCLIqzvHKiIiDeBj1F82LuJYl7+E6nuLorf+FakcTwDXJDqXgHmA9dRTN21AT+rsT82SlRMs5k1V7oi3UkxdfPicO3NbP/4St+aRtLHJB2VPhP4NvA0xZ1CZjZKHPrWTHMpPkDdQvGr/4Lwr55mo8rTO2ZmGfGVvplZRpr9R6yGdOKJJ8bUqVOb3Q0zs4PKunXrXomIil/2e0eH/tSpU+nu7m52N8zMDiqSXq5W5+kdM7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMvKO/kWt2MJt6xY+b3YW3eem6jxzQ9u/EMcGBjysnvtI3M8uIr/QPMu/EKy1fZZkdPHylb2aWkd/pK31fFZuZ7et3OvTt4PBOPDmDT9A5eSf+Hxyt/3+e3jEzy4hD38wsIzWFvqQvS1ov6RlJt0s6QtI0SQ9L2ijpDkmHpbaHp/WeVD+1tJ8rU/nzkmaPzpDMzKyaYUNf0iTgS0B7RLwPGAMsAL4FXB8RbcAOYGHaZCGwIyJOAa5P7ZB0WtrudGAOcKOkMSM7HDMzG0qt0zstwJGSWoCjgK3AecCqVN8JzEvLc9M6qX6mJKXyFRHxRkS8CPQAZx34EMzMrFbDhn5E/BPwbWATRdjvAtYBOyNib2rWC0xKy5OAzWnbvan9CeXyCtv8lqRFkroldff19e3PmMzMrIpapnfGU1ylTwPeBYwFLqjQNAY2qVJXrXzfgoilEdEeEe2tra3Ddc/MzOpQy/TO+cCLEdEXEf8C3An8ETAuTfcATAa2pOVeYApAqj8O6C+XV9jGzMwaoJbQ3wTMkHRUmpufCTwLPABclNp0AHen5dVpnVR/f0REKl+Q7u6ZBrQBj4zMMMzMrBbDfiM3Ih6WtAp4DNgLPA4sBX4MrJD0zVS2LG2yDLhVUg/FFf6CtJ/1klZSnDD2Aosj4s0RHo+ZmQ2hpj/DEBFLgCWDil+gwt03EfE6ML/Kfq4Frq2zj2ZmNkL8jVwzs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLSC3PyD1V0hOl12uSLpd0vKQuSRvT+/jUXpJukNQj6SlJ00v76kjtN0rqqH5UMzMbDcOGfkQ8HxFnRMQZwB8Ce4C7gCuANRHRBqxJ61A8NL0tvRYBNwFIOp7iQSxnUzx8ZcnAicLMzBqj3umdmcDPI+JlYC7Qmco7gXlpeS5wSxTWUjxA/SRgNtAVEf0RsQPoAuYc8AjMzKxm9Yb+AuD2tDwxIrYCpPcJqXwSsLm0TW8qq1a+D0mLJHVL6u7r66uze2ZmNpSaQ1/SYcDHgb8drmmFshiifN+CiKUR0R4R7a2trbV2z8zMalDPlf4FwGMRsS2tb0vTNqT37am8F5hS2m4ysGWIcjMza5B6Qv+TvDW1A7AaGLgDpwO4u1R+SbqLZwawK03/3AfMkjQ+fYA7K5WZmVmDtNTSSNJRwIeBz5WKrwNWSloIbALmp/J7gQuBHoo7fS4FiIh+SdcAj6Z2V0dE/wGPwMzMalZT6EfEHuCEQWWvUtzNM7htAIur7Gc5sLz+bpqZ2UjwN3LNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OM1BT6ksZJWiXpOUkbJH1A0vGSuiRtTO/jU1tJukFSj6SnJE0v7acjtd8oqaP6Ec3MbDTUeqX/PeAnEfEHwPuBDcAVwJqIaAPWpHUoHqDell6LgJsAJB0PLAHOBs4ClgycKMzMrDGGDX1JxwIfApYBRMSvI2InMBfoTM06gXlpeS5wSxTWAuMknQTMBroioj8idgBdwJwRHY2ZmQ2pliv99wB9wN9IelzSzZLGAhMjYitAep+Q2k8CNpe2701l1cr3IWmRpG5J3X19fXUPyMzMqqsl9FuA6cBNEXEm8CvemsqpRBXKYojyfQsilkZEe0S0t7a21tA9MzOrVS2h3wv0RsTDaX0VxUlgW5q2Ib1vL7WfUtp+MrBliHIzM2uQYUM/In4BbJZ0aiqaCTwLrAYG7sDpAO5Oy6uBS9JdPDOAXWn65z5glqTx6QPcWanMzMwapKXGdl8EbpN0GPACcCnFCWOlpIXAJmB+ansvcCHQA+xJbYmIfknXAI+mdldHRP+IjMLMzGpSU+hHxBNAe4WqmRXaBrC4yn6WA8vr6aCZmY0cfyPXzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMlJT6Et6SdLTkp6Q1J3KjpfUJWljeh+fyiXpBkk9kp6SNL20n47UfqOkjmrHMzOz0VHPlf6/jYgzImLgYSpXAGsiog1Yw1sPS78AaEuvRcBNUJwkgCXA2cBZwJKBE4WZmTXGgUzvzAU603InMK9UfksU1gLj0oPTZwNdEdEfETuALmDOARzfzMzqVGvoB/D3ktZJWpTKJqYHnpPeJ6TyScDm0ra9qaxa+T4kLZLULam7r6+v9pGYmdmwan0w+jkRsUXSBKBL0nNDtFWFshiifN+CiKXAUoD29va31ZuZ2f6r6Uo/Irak9+3AXRRz8tvStA3pfXtq3gtMKW0+GdgyRLmZmTXIsKEvaaykYwaWgVnAM8BqYOAOnA7g7rS8Grgk3cUzA9iVpn/uA2ZJGp8+wJ2VyszMrEFqmd6ZCNwlaaD9DyPiJ5IeBVZKWghsAuan9vcCFwI9wB7gUoCI6Jd0DfBoand1RPSP2EjMzGxYw4Z+RLwAvL9C+avAzArlASyusq/lwPL6u2lmZiPB38g1M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwyUnPoSxoj6XFJ96T1aZIelrRR0h2SDkvlh6f1nlQ/tbSPK1P585Jmj/RgzMxsaPVc6V8GbCitfwu4PiLagB3AwlS+ENgREacA16d2SDoNWACcDswBbpQ05sC6b2Zm9agp9CVNBj4C3JzWBZwHrEpNOoF5aXluWifVz0zt5wIrIuKNiHiR4hm6Z43EIMzMrDa1Xul/F/gq8Ju0fgKwMyL2pvVeYFJangRsBkj1u1L735ZX2Oa3JC2S1C2pu6+vr46hmJnZcIYNfUkfBbZHxLpycYWmMUzdUNu8VRCxNCLaI6K9tbV1uO6ZmVkdWmpocw7wcUkXAkcAx1Jc+Y+T1JKu5icDW1L7XmAK0CupBTgO6C+VDyhvY2ZmDTDslX5EXBkRkyNiKsUHsfdHxJ8ADwAXpWYdwN1peXVaJ9XfHxGRyheku3umAW3AIyM2EjMzG1YtV/rVfA1YIembwOPAslS+DLhVUg/FFf4CgIhYL2kl8CywF1gcEW8ewPHNzKxOdYV+RDwIPJiWX6DC3TcR8Towv8r21wLX1ttJMzMbGf5GrplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWWklmfkHiHpEUlPSlov6apUPk3Sw5I2SrpD0mGp/PC03pPqp5b2dWUqf17S7NEalJmZVVbLlf4bwHkR8X7gDGCOpBnAt4DrI6IN2AEsTO0XAjsi4hTg+tQOSadRPEXrdGAOcKOkMSM5GDMzG1otz8iNiNidVg9NrwDOA1al8k5gXlqem9ZJ9TMlKZWviIg3IuJFoIcKT94yM7PRU9OcvqQxkp4AtgNdwM+BnRGxNzXpBSal5UnAZoBUvws4oVxeYZvysRZJ6pbU3dfXV/+IzMysqppCPyLejIgzgMkUV+fvrdQsvatKXbXywcdaGhHtEdHe2tpaS/fMzKxGdd29ExE7KR6MPgMYJ2ngweqTgS1puReYApDqjwP6y+UVtjEzswao5e6dVknj0vKRwPnABuAB4KLUrAO4Oy2vTuuk+vsjIlL5gnR3zzSgDXhkpAZiZmbDaxm+CScBnelOm0OAlRFxj6RngRWSvgk8DixL7ZcBt0rqobjCXwAQEeslrQSeBfYCiyPizZEdjpmZDWXY0I+Ip4AzK5S/QIW7byLidWB+lX1dC1xbfzfNzGwk+Bu5ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRmp5XOIUSQ9I2iBpvaTLUvnxkrokbUzv41O5JN0gqUfSU5Kml/bVkdpvlNRR7ZhmZjY6arnS3wt8JSLeS/FA9MWSTgOuANZERBuwJq0DXEDx/Ns2YBFwExQnCWAJcDbFE7eWDJwozMysMYYN/YjYGhGPpeVfUjwUfRIwF+hMzTqBeWl5LnBLFNYC4ySdBMwGuiKiPyJ2AF3AnBEdjZmZDamuOX1JUymel/swMDEitkJxYgAmpGaTgM2lzXpTWbXywcdYJKlbUndfX1893TMzs2HUHPqSjgZ+BFweEa8N1bRCWQxRvm9BxNKIaI+I9tbW1lq7Z2ZmNagp9CUdShH4t0XEnal4W5q2Ib1vT+W9wJTS5pOBLUOUm5lZg9Ry946AZcCGiPhOqWo1MHAHTgdwd6n8knQXzwxgV5r+uQ+YJWl8+gB3ViozM7MGaamhzTnAxcDTkp5IZV8HrgNWSloIbALmp7p7gQuBHmAPcClARPRLugZ4NLW7OiL6R2QUZmZWk2FDPyJ+SuX5eICZFdoHsLjKvpYDy+vpoJmZjRx/I9fMLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwyUsuTs5ZL2i7pmVLZ8ZK6JG1M7+NTuSTdIKlH0lOSppe26UjtN0rqqHQsMzMbXbVc6f9PYM6gsiuANRHRBqxJ6wAXAG3ptQi4CYqTBLAEOBs4C1gycKIwM7PGGTb0I+IhYPBjDecCnWm5E5hXKr8lCmuBcemh6bOBrojoj4gdQBdvP5GYmdko2985/YnpYeek9wmpfBKwudSuN5VVK38bSYskdUvq7uvr28/umZlZJSP9QW6lZ+nGEOVvL4xYGhHtEdHe2to6op0zM8vd/ob+tjRtQ3rfnsp7gSmldpOBLUOUm5lZA+1v6K8GBu7A6QDuLpVfku7imQHsStM/9wGzJI1PH+DOSmVmZtZALcM1kHQ7cC5woqReirtwrgNWSloIbALmp+b3AhcCPcAe4FKAiOiXdA3waGp3dUQM/nDYzMxG2bChHxGfrFI1s0LbABZX2c9yYHldvTMzsxHlb+SamWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZaXjoS5oj6XlJPZKuaPTxzcxy1tDQlzQG+B/ABcBpwCclndbIPpiZ5azRV/pnAT0R8UJE/BpYAcxtcB/MzLKl4rG2DTqYdBEwJyI+m9YvBs6OiC+U2iwCFqXVU4Hnh9jlicAro9Tdg4HH7/F7/PkaavwnR0RrpYphH4w+wlShbJ+zTkQsBZbWtDOpOyLaR6JjByOP3+P3+D3+erdr9PROLzCltD4Z2NLgPpiZZavRof8o0CZpmqTDgAXA6gb3wcwsWw2d3omIvZK+ANwHjAGWR8T6A9hlTdNAv8M8/rx5/Hnbr/E39INcMzNrLn8j18wsIw59M7OMHHShL2m5pO2Snml2X5pB0hRJD0jaIGm9pMua3adGknSEpEckPZnGf1Wz+9QMksZIelzSPc3uS6NJeknS05KekNTd7P40mqRxklZJei7lwAfq2v5gm9OX9CFgN3BLRLyv2f1pNEknASdFxGOSjgHWAfMi4tkmd60hJAkYGxG7JR0K/BS4LCLWNrlrDSXpPwLtwLER8dFm96eRJL0EtEdEll/MktQJ/N+IuDndBXlUROysdfuD7ko/Ih4C+pvdj2aJiK0R8Vha/iWwAZjU3F41ThR2p9VD0+vgunI5QJImAx8Bbm52X6yxJB0LfAhYBhARv64n8OEgDH17i6SpwJnAw83tSWOlqY0ngO1AV0RkNX7gu8BXgd80uyNNEsDfS1qX/mxLTt4D9AF/k6b3bpY0tp4dOPQPUpKOBn4EXB4RrzW7P40UEW9GxBkU3+g+S1I203ySPgpsj4h1ze5LE50TEdMp/lrv4jTlm4sWYDpwU0ScCfwKqOtP1Dv0D0JpLvtHwG0RcWez+9Ms6dfaB4E5Te5KI50DfDzNa68AzpP0g+Z2qbEiYkt63w7cRfHXe3PRC/SWfrtdRXESqJlD/yCTPshcBmyIiO80uz+NJqlV0ri0fCRwPvBcc3vVOBFxZURMjoipFH/G5P6I+FSTu9UwksamGxhI0xqzgGzu5IuIXwCbJZ2aimYCdd3E0ei/snnAJN0OnAucKKkXWBIRy5rbq4Y6B7gYeDrNawN8PSLubWKfGukkoDM9kOcQYGVEZHfbYsYmAncV1z60AD+MiJ80t0sN90XgtnTnzgvApfVsfNDdsmlmZvvP0ztmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWkf8Pb1p0De9pacwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 50000\n",
    "die = Die()\n",
    "\n",
    "samples = [die.role_once() for _ in range(n_samples)]\n",
    "\n",
    "plt.hist(samples,rwidth=0.7,bins=6)\n",
    "plt.title(\"Histogram of the six faced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    We see that the bars have pretty similar sizes. Hence, the die is fair.\n",
    "    <\\font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B : Computation of the optimal strategy for each player assuming a perfectly fair die\n",
    "<font size=\"4\">\n",
    "As stated in the problem set, in this scenario we assume that Player 2 knows a priori the sequence chosen by Player 1. Furthermore we assume that both Players are rational, that is they are always trying to win. \n",
    "    \n",
    "Now, assume that Player 1 choses some sequence, let say, $S_1$. Then, Player 2 can win by choosing a sequence $S_2$, that maximize the follwing probability  $$\n",
    "\\max_{S_2} P[S_1][S_2] = \\max_{S_2}P(S_2 \\text{ appears before } S_1)\n",
    "$$\n",
    "    \n",
    "that is, the optimal sequence for Player 2 is: $\\arg \\max_{S_2} P[S_1][S_2]$, while $S_1$ is known by assumption.  \n",
    "    \n",
    "Similary, Player 1 knows that Player 2 is rational. Then, Player 1 choses his optimal sequence by solving $$\n",
    "\\min_{S_1} P[S_1][S_2] = \\min_{S_1} P(S_2 \\text{ appears before } S_1), \\quad \\forall S_2\n",
    "$$\n",
    "this means that Player 1 need to chose the strategy that minimize the probability of Player 2 to win. Note that \n",
    "    $$\n",
    "    \\min_{S_1} P[S_1][S_2]\\leq \\min_{S_1} \\max_{S_2} P[S_1][S_2], \\quad \\forall S_2\n",
    "    $$\n",
    "Hence, the optimal sequence for Player 1 is: $\\arg\\min_{S_1} \\max_{S_2} P[S_1][S_2]$      \n",
    "Now, the last step that we need to compute the optimal strategy for each player is to find the matrix $P[S_1][S_2] = P(S_2 \\text{ appears before } S_1) \\quad \\forall S_1,S_2$\n",
    "    \n",
    "In order to do so, we will use the Monte-Carlo method. where for each $P_1,P_2$ we will run $N$ experiments to estimate $P[S_1][S_2] = P(S_2 \\text{ appears before } S_1)$. By Law of Large Numbers, we now that this estimation converges to the real probability if $N$ is arbitrarily large. The code follows: \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possible outcomes\n",
    "outcomes = [\"E\",\"O\"]\n",
    "\n",
    "#All possible sequences \n",
    "seqs = [\"\".join([a,b,c]) for a in outcomes for b in outcomes for c in outcomes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "#Simulator of the game\n",
    "def play_game(p1,p2):\n",
    "    rolls = \"\"\n",
    "    winners_history = []\n",
    "    for n in range(n_samples):\n",
    "        i = 0\n",
    "        rolls = \"\"\n",
    "        while True:\n",
    "            rolls += die()\n",
    "            if p1 in rolls:\n",
    "                winners_history.append(1)\n",
    "                break\n",
    "            if p2 in rolls:\n",
    "                winners_history.append(2)\n",
    "                break\n",
    "                \n",
    "            if i>1e5:\n",
    "                break\n",
    "            i += 1\n",
    "            \n",
    "    return winners_history\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_dict = {}\n",
    "#estimate the P\n",
    "for p1 in seqs:\n",
    "    for p2 in seqs:\n",
    "        if p1 == p2:\n",
    "            continue\n",
    "        winner = play_game(p1,p2)\n",
    "        #Estimate of probability that Player 1 wins\n",
    "        prob1 = np.sum((np.array(winner)== 1).astype(np.float))/len(winner)\n",
    "        #Estimate of probability that Player 2 wins\n",
    "        prob2 = np.sum((np.array(winner)== 2).astype(np.float))/len(winner)\n",
    "        strategy_dict[(p1,p2)] = (prob1,prob2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction of P such that \n",
    "#P[S1][S2] = P(S_2 appears before S_1) that Prob Player 2 to win \n",
    "\n",
    "P = {}\n",
    "for (s1,s2),(prob1,prob2) in strategy_dict.items():\n",
    "    if P.get(s1) is None:\n",
    "        P[s1] = dict()\n",
    "        \n",
    "    P[s1][s2] = prob2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "Now, let find the optimal strategies. But before doing that, let pick an example and see what happens. \n",
    "\n",
    "    \n",
    "Assume that Player 1 chooses the sequence \"EEE\", the otimal move for Player 2 is: \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EEO': 0.4997,\n",
       " 'EOE': 0.593,\n",
       " 'EOO': 0.5989,\n",
       " 'OEE': 0.8762,\n",
       " 'OEO': 0.5892,\n",
       " 'OOE': 0.7041,\n",
       " 'OOO': 0.501}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[\"EEE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal move for Player 2 is 'OEE' \n"
     ]
    }
   ],
   "source": [
    "#Get sequence with max probabily of wining\n",
    "optim_seq = max(P[\"EEE\"], key = lambda key: P[\"EEE\"][key])\n",
    "print(\"Optimal move for Player 2 is '{}' \".format(optim_seq))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "Recall that the optimal strategy for Player 1 is $$\n",
    "    \\min_{S_1} P[S_1][S_2]\\leq \\min_{S_1} \\max_{S_2} P[S_1][S_2], \\quad \\forall S_2\n",
    "    $$\n",
    " Thus the optimal sequence for Player 1 is:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolut best winner sequence for Player 1 is 'EOE' \n"
     ]
    }
   ],
   "source": [
    "absolute_optimal_strategy_for_player_1 = S1 = min(P, key= lambda s1: max(P[s1], key=lambda s2: P[s1][s2]))\n",
    "print(\"Absolut best winner sequence for Player 1 is '{}' \".format(S1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "Recall that the optimal strategy for Player 1 is $$\n",
    "    \\max_{S_2} P[S^*_1][S_2]\n",
    "    $$\n",
    " While $S^*_1$ is the best strategy for Player 2. Thus the optimal sequence for Player 1 is:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolut best winner sequence for Player 2 is 'EEO' \n"
     ]
    }
   ],
   "source": [
    "absolute_optimal_strategy_for_player_2 = S2 =  max(P[S1], key=lambda S2: P[S1][S2])\n",
    "print(\"Absolut best winner sequence for Player 2 is '{}' \".format(S2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C : Probability Player 2 (AI agent) will win, given the optimal strategies above is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Player 2 (AI agent) will win, given the optimal strategies above is 66.74%\n"
     ]
    }
   ],
   "source": [
    "print(\"Probability Player 2 (AI agent) will win, given the optimal strategies above is {:0.2f}%\" .format(100*P[absolute_optimal_strategy_for_player_1][absolute_optimal_strategy_for_player_2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    As we may, a priori, predicted, Player 2 should have more chance to win. This is, obviously, because of the advantage of the a priori information.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D : The game when Player 2 does not have any information about the choices of Player 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "   Now that Player 2 does not have anymore the advantage of information, its optimal strategy is chosen such that the following is maximized:\n",
    "    $$\n",
    "    \\max_{S_2} P[S_1][S_2] = \\max_{S_2}P(S_2 \\text{ appears before } S_1), \\quad \\forall S_1\n",
    "$$\n",
    "    Note that,\n",
    "    $$\n",
    "    \\max_{S_2} \\min_{S_1}P[S_1][S_2]\\leq \\max_{S_2} P[S_1][S_2], \\quad \\forall S_1\n",
    "$$\n",
    "Hence, the optimal sequence for Player 2 is: $\\arg\\max_{S_2} \\min_{S_1}P[S_1][S_2]$\n",
    "\n",
    "The way to compute optimal strategy for Player 1 remains unchanged, that is solving the following minimization problem:\n",
    " $$\n",
    "\\min_{S_1} P[S_1][S_2]\\leq \\min_{S_1} \\max_{S_2} P[S_1][S_2], \\quad \\forall S_2 \n",
    "$$\n",
    "Hence, the optimal sequence for Player 1 is: $\\arg\\min_{S_1} \\max_{S_2}P[S_1][S_2]$\n",
    "    \n",
    "Note that, solving these two equations and finding the optimal strategies lead to a Nash equilibria. That is, assuming that the Players are rational, each Player won't have any interest in changing his strategy after solving the $\\min\\max$ problem above. \n",
    "    \n",
    "\n",
    "The new optimal strategies for each player is\n",
    " \n",
    " </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolut best winner sequence for Player 1 is 'EOE' \n",
      "Absolut best winner sequence for Player 2 is 'EEO' \n",
      "Probability Player 2 (AI agent) will win, given the optimal strategies above is 66.74%\n"
     ]
    }
   ],
   "source": [
    "absolute_optimal_strategy_for_player_2 = S2 = max(P, key= lambda s1: min(P[s1], key=lambda s2: P[s1][s2]))\n",
    "absolute_optimal_strategy_for_player_1 = S1 = min(P, key= lambda s1: max(P[s1], key=lambda s2: P[s1][s2]))\n",
    "\n",
    "\n",
    "print(\"Absolut best winner sequence for Player 1 is '{}' \".format(S1))\n",
    "print(\"Absolut best winner sequence for Player 2 is '{}' \".format(S2))\n",
    "print(\"Probability Player 2 (AI agent) will win, given the optimal strategies above is {:0.2f}%\" .format(100*P[S1][S2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    " Surprisingly, the results of optimality are exactly the same as in the case of a priori known strategy of Player 1 by Player 2. This can be explained very simply by the fact that the main assumption of rationnality , that is, both players are rationnal leads to a Nash Equilibria that can be computed independantly of the shared information. However, if Player 1, in the first case when the information is shared, decides to not be rationnal, then the information is crucial for Player 2.\n",
    "  <\\font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
